{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "# Get the parent directory of the current working directory\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "# Append the parent directory to the Python path\n",
    "sys.path.append(parent_directory)\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from CustomAugment import RandomFlip, RandomRotation, RandomBrightnessContrast\n",
    "from CustomAugment import Normalize, RandomGaussianNoise, RandomAugmentation\n",
    "import mediapipe as mp\n",
    "\n",
    "face_detection = mp.solutions.face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgpath = parent_directory+'/dataset/test/'\n",
    "\n",
    "\n",
    "img = Image.open(imgpath+'test1.jpg')\n",
    "\n",
    "img = np.array(img)\n",
    "\n",
    "try:\n",
    "    results = face_detection.process(img)\n",
    "    # face, prob = mtcnn(img, return_prob=True)\n",
    "\n",
    "    if results.detections:\n",
    "        # Get the first detected face\n",
    "        first_face = results.detections[0]\n",
    "\n",
    "        bbox = first_face.location_data.relative_bounding_box\n",
    "        x, y, w, h = int(bbox.xmin * img.shape[1]), int(bbox.ymin * img.shape[0]), \\\n",
    "                        int(bbox.width * img.shape[1]), int(bbox.height * img.shape[0])\n",
    "\n",
    "        # Add padding to the image\n",
    "        border = max(w, h)  # Use the maximum of width and height as the border size\n",
    "        img_padded = cv2.copyMakeBorder(img, border, border, border, border, cv2.BORDER_CONSTANT,\n",
    "                                        value=[0, 0, 0])\n",
    "\n",
    "        # Crop the face region from the padded image\n",
    "        face_image = img_padded[y + border:y + h + border, x + border:x + w + border]\n",
    "\n",
    "        img = Image.fromarray(face_image)\n",
    "\n",
    "    else:\n",
    "        print('.', end='')\n",
    "        # print(idx_to_class[label])\n",
    "        # print(\"No Face detected!\")\n",
    "        # pass\n",
    "except ValueError:\n",
    "    print(\"Error detection!\")\n",
    "\n",
    "# Save the image\n",
    "img.save(imgpath+'crop.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    RandomBrightnessContrast(brightness_range=(0.5, 1.5), contrast_range=(0.5, 1.5)),\n",
    "])\n",
    "\n",
    "img = img_transform(img)\n",
    "# Save the image\n",
    "img.save(imgpath+'brightcontr.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    RandomGaussianNoise(mean=0.0, std_range=(0.01, 0.8)),\n",
    "])\n",
    "\n",
    "img = img_transform(img)\n",
    "# Save the image\n",
    "img.save(imgpath+'noise.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    transforms.ColorJitter(saturation=0.1, hue=0.1),\n",
    "])\n",
    "\n",
    "img = img_transform(img)\n",
    "# Save the image\n",
    "img.save(imgpath+'jitter.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    RandomRotation(angles=(-20, -1, 0, 1, 20)),\n",
    "])\n",
    "\n",
    "img = img_transform(img)\n",
    "# Save the image\n",
    "img.save(imgpath+'rotation.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    RandomFlip(p=0.5),\n",
    "])\n",
    "\n",
    "img = img_transform(img)\n",
    "# Save the image\n",
    "img.save(imgpath+'flip.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize((160, 160)),\n",
    "])\n",
    "\n",
    "img = img_transform(img)\n",
    "# Save the image\n",
    "img.save(imgpath+'resize.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "img = img_transform(img)\n",
    "# Save the image\n",
    "img.save(imgpath+'normalize.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
